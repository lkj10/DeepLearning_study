{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hnrAnCc71oP",
        "outputId": "e658cb8b-dea2-4f9d-c3f0-24193e3f937b"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 1.3MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.34.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlHWLS7I75E6",
        "outputId": "b1f77579-1093-43a1-af28-8b223053d70d"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
        "\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-4a2cbbe30971>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaf3InWr8LgT"
      },
      "source": [
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "X_img = tf.reshape(X, [-1, 28, 28, 1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGrhcI2F8cfU"
      },
      "source": [
        "#Convolution Layer 1\n",
        "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
        "CL1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
        "CL1 = tf.nn.relu(CL1)\n",
        "#Pooling Layer 1\n",
        "PL1 = tf.nn.max_pool(CL1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "#Convolution Layer 2\n",
        "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
        "CL2 = tf.nn.conv2d(PL1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
        "CL2 = tf.nn.relu(CL2)\n",
        "#Pooling Layer 2\n",
        "PL2 = tf.nn.max_pool(CL2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "\n",
        "#Fully Connected (FC) Layer\n",
        "L_flat = tf.reshape(PL2, [-1, 7*7*64])\n",
        "W3 = tf.Variable(tf.random_normal([7*7*64,10], stddev=0.01))\n",
        "b3 = tf.Variable(tf.random_normal([10]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxzUAAmk8v0w"
      },
      "source": [
        "model_LC = tf.matmul(L_flat, W3) + b3\n",
        "model = tf.nn.softmax(model_LC)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_LC, labels = Y))\n",
        "train = tf.train.AdamOptimizer(0.01).minimize(cost)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrM0geNN9mPd"
      },
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1)), tf.float32))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td17LyRe9nYa",
        "outputId": "c54bb55b-7400-4a91-ef13-bb3ebf021728"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  #Train\n",
        "  t1 = time.time()\n",
        "  for epoch in range(training_epochs):\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    for i in range(total_batch):\n",
        "      train_images, train_labels = mnist.train.next_batch(batch_size)\n",
        "      c, _ = sess.run([cost, train], feed_dict = {X: train_images, Y: train_labels})\n",
        "      if i % 10 == 0:\n",
        "        print(epoch, i)\n",
        "  t2 = time.time()\n",
        "  print(t2 - t1)\n",
        "  print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "0 10\n",
            "0 20\n",
            "0 30\n",
            "0 40\n",
            "0 50\n",
            "0 60\n",
            "0 70\n",
            "0 80\n",
            "0 90\n",
            "0 100\n",
            "0 110\n",
            "0 120\n",
            "0 130\n",
            "0 140\n",
            "0 150\n",
            "0 160\n",
            "0 170\n",
            "0 180\n",
            "0 190\n",
            "0 200\n",
            "0 210\n",
            "0 220\n",
            "0 230\n",
            "0 240\n",
            "0 250\n",
            "0 260\n",
            "0 270\n",
            "0 280\n",
            "0 290\n",
            "0 300\n",
            "0 310\n",
            "0 320\n",
            "0 330\n",
            "0 340\n",
            "0 350\n",
            "0 360\n",
            "0 370\n",
            "0 380\n",
            "0 390\n",
            "0 400\n",
            "0 410\n",
            "0 420\n",
            "0 430\n",
            "0 440\n",
            "0 450\n",
            "0 460\n",
            "0 470\n",
            "0 480\n",
            "0 490\n",
            "0 500\n",
            "0 510\n",
            "0 520\n",
            "0 530\n",
            "0 540\n",
            "1 0\n",
            "1 10\n",
            "1 20\n",
            "1 30\n",
            "1 40\n",
            "1 50\n",
            "1 60\n",
            "1 70\n",
            "1 80\n",
            "1 90\n",
            "1 100\n",
            "1 110\n",
            "1 120\n",
            "1 130\n",
            "1 140\n",
            "1 150\n",
            "1 160\n",
            "1 170\n",
            "1 180\n",
            "1 190\n",
            "1 200\n",
            "1 210\n",
            "1 220\n",
            "1 230\n",
            "1 240\n",
            "1 250\n",
            "1 260\n",
            "1 270\n",
            "1 280\n",
            "1 290\n",
            "1 300\n",
            "1 310\n",
            "1 320\n",
            "1 330\n",
            "1 340\n",
            "1 350\n",
            "1 360\n",
            "1 370\n",
            "1 380\n",
            "1 390\n",
            "1 400\n",
            "1 410\n",
            "1 420\n",
            "1 430\n",
            "1 440\n",
            "1 450\n",
            "1 460\n",
            "1 470\n",
            "1 480\n",
            "1 490\n",
            "1 500\n",
            "1 510\n",
            "1 520\n",
            "1 530\n",
            "1 540\n",
            "2 0\n",
            "2 10\n",
            "2 20\n",
            "2 30\n",
            "2 40\n",
            "2 50\n",
            "2 60\n",
            "2 70\n",
            "2 80\n",
            "2 90\n",
            "2 100\n",
            "2 110\n",
            "2 120\n",
            "2 130\n",
            "2 140\n",
            "2 150\n",
            "2 160\n",
            "2 170\n",
            "2 180\n",
            "2 190\n",
            "2 200\n",
            "2 210\n",
            "2 220\n",
            "2 230\n",
            "2 240\n",
            "2 250\n",
            "2 260\n",
            "2 270\n",
            "2 280\n",
            "2 290\n",
            "2 300\n",
            "2 310\n",
            "2 320\n",
            "2 330\n",
            "2 340\n",
            "2 350\n",
            "2 360\n",
            "2 370\n",
            "2 380\n",
            "2 390\n",
            "2 400\n",
            "2 410\n",
            "2 420\n",
            "2 430\n",
            "2 440\n",
            "2 450\n",
            "2 460\n",
            "2 470\n",
            "2 480\n",
            "2 490\n",
            "2 500\n",
            "2 510\n",
            "2 520\n",
            "2 530\n",
            "2 540\n",
            "3 0\n",
            "3 10\n",
            "3 20\n",
            "3 30\n",
            "3 40\n",
            "3 50\n",
            "3 60\n",
            "3 70\n",
            "3 80\n",
            "3 90\n",
            "3 100\n",
            "3 110\n",
            "3 120\n",
            "3 130\n",
            "3 140\n",
            "3 150\n",
            "3 160\n",
            "3 170\n",
            "3 180\n",
            "3 190\n",
            "3 200\n",
            "3 210\n",
            "3 220\n",
            "3 230\n",
            "3 240\n",
            "3 250\n",
            "3 260\n",
            "3 270\n",
            "3 280\n",
            "3 290\n",
            "3 300\n",
            "3 310\n",
            "3 320\n",
            "3 330\n",
            "3 340\n",
            "3 350\n",
            "3 360\n",
            "3 370\n",
            "3 380\n",
            "3 390\n",
            "3 400\n",
            "3 410\n",
            "3 420\n",
            "3 430\n",
            "3 440\n",
            "3 450\n",
            "3 460\n",
            "3 470\n",
            "3 480\n",
            "3 490\n",
            "3 500\n",
            "3 510\n",
            "3 520\n",
            "3 530\n",
            "3 540\n",
            "4 0\n",
            "4 10\n",
            "4 20\n",
            "4 30\n",
            "4 40\n",
            "4 50\n",
            "4 60\n",
            "4 70\n",
            "4 80\n",
            "4 90\n",
            "4 100\n",
            "4 110\n",
            "4 120\n",
            "4 130\n",
            "4 140\n",
            "4 150\n",
            "4 160\n",
            "4 170\n",
            "4 180\n",
            "4 190\n",
            "4 200\n",
            "4 210\n",
            "4 220\n",
            "4 230\n",
            "4 240\n",
            "4 250\n",
            "4 260\n",
            "4 270\n",
            "4 280\n",
            "4 290\n",
            "4 300\n",
            "4 310\n",
            "4 320\n",
            "4 330\n",
            "4 340\n",
            "4 350\n",
            "4 360\n",
            "4 370\n",
            "4 380\n",
            "4 390\n",
            "4 400\n",
            "4 410\n",
            "4 420\n",
            "4 430\n",
            "4 440\n",
            "4 450\n",
            "4 460\n",
            "4 470\n",
            "4 480\n",
            "4 490\n",
            "4 500\n",
            "4 510\n",
            "4 520\n",
            "4 530\n",
            "4 540\n",
            "5 0\n",
            "5 10\n",
            "5 20\n",
            "5 30\n",
            "5 40\n",
            "5 50\n",
            "5 60\n",
            "5 70\n",
            "5 80\n",
            "5 90\n",
            "5 100\n",
            "5 110\n",
            "5 120\n",
            "5 130\n",
            "5 140\n",
            "5 150\n",
            "5 160\n",
            "5 170\n",
            "5 180\n",
            "5 190\n",
            "5 200\n",
            "5 210\n",
            "5 220\n",
            "5 230\n",
            "5 240\n",
            "5 250\n",
            "5 260\n",
            "5 270\n",
            "5 280\n",
            "5 290\n",
            "5 300\n",
            "5 310\n",
            "5 320\n",
            "5 330\n",
            "5 340\n",
            "5 350\n",
            "5 360\n",
            "5 370\n",
            "5 380\n",
            "5 390\n",
            "5 400\n",
            "5 410\n",
            "5 420\n",
            "5 430\n",
            "5 440\n",
            "5 450\n",
            "5 460\n",
            "5 470\n",
            "5 480\n",
            "5 490\n",
            "5 500\n",
            "5 510\n",
            "5 520\n",
            "5 530\n",
            "5 540\n",
            "6 0\n",
            "6 10\n",
            "6 20\n",
            "6 30\n",
            "6 40\n",
            "6 50\n",
            "6 60\n",
            "6 70\n",
            "6 80\n",
            "6 90\n",
            "6 100\n",
            "6 110\n",
            "6 120\n",
            "6 130\n",
            "6 140\n",
            "6 150\n",
            "6 160\n",
            "6 170\n",
            "6 180\n",
            "6 190\n",
            "6 200\n",
            "6 210\n",
            "6 220\n",
            "6 230\n",
            "6 240\n",
            "6 250\n",
            "6 260\n",
            "6 270\n",
            "6 280\n",
            "6 290\n",
            "6 300\n",
            "6 310\n",
            "6 320\n",
            "6 330\n",
            "6 340\n",
            "6 350\n",
            "6 360\n",
            "6 370\n",
            "6 380\n",
            "6 390\n",
            "6 400\n",
            "6 410\n",
            "6 420\n",
            "6 430\n",
            "6 440\n",
            "6 450\n",
            "6 460\n",
            "6 470\n",
            "6 480\n",
            "6 490\n",
            "6 500\n",
            "6 510\n",
            "6 520\n",
            "6 530\n",
            "6 540\n",
            "7 0\n",
            "7 10\n",
            "7 20\n",
            "7 30\n",
            "7 40\n",
            "7 50\n",
            "7 60\n",
            "7 70\n",
            "7 80\n",
            "7 90\n",
            "7 100\n",
            "7 110\n",
            "7 120\n",
            "7 130\n",
            "7 140\n",
            "7 150\n",
            "7 160\n",
            "7 170\n",
            "7 180\n",
            "7 190\n",
            "7 200\n",
            "7 210\n",
            "7 220\n",
            "7 230\n",
            "7 240\n",
            "7 250\n",
            "7 260\n",
            "7 270\n",
            "7 280\n",
            "7 290\n",
            "7 300\n",
            "7 310\n",
            "7 320\n",
            "7 330\n",
            "7 340\n",
            "7 350\n",
            "7 360\n",
            "7 370\n",
            "7 380\n",
            "7 390\n",
            "7 400\n",
            "7 410\n",
            "7 420\n",
            "7 430\n",
            "7 440\n",
            "7 450\n",
            "7 460\n",
            "7 470\n",
            "7 480\n",
            "7 490\n",
            "7 500\n",
            "7 510\n",
            "7 520\n",
            "7 530\n",
            "7 540\n",
            "8 0\n",
            "8 10\n",
            "8 20\n",
            "8 30\n",
            "8 40\n",
            "8 50\n",
            "8 60\n",
            "8 70\n",
            "8 80\n",
            "8 90\n",
            "8 100\n",
            "8 110\n",
            "8 120\n",
            "8 130\n",
            "8 140\n",
            "8 150\n",
            "8 160\n",
            "8 170\n",
            "8 180\n",
            "8 190\n",
            "8 200\n",
            "8 210\n",
            "8 220\n",
            "8 230\n",
            "8 240\n",
            "8 250\n",
            "8 260\n",
            "8 270\n",
            "8 280\n",
            "8 290\n",
            "8 300\n",
            "8 310\n",
            "8 320\n",
            "8 330\n",
            "8 340\n",
            "8 350\n",
            "8 360\n",
            "8 370\n",
            "8 380\n",
            "8 390\n",
            "8 400\n",
            "8 410\n",
            "8 420\n",
            "8 430\n",
            "8 440\n",
            "8 450\n",
            "8 460\n",
            "8 470\n",
            "8 480\n",
            "8 490\n",
            "8 500\n",
            "8 510\n",
            "8 520\n",
            "8 530\n",
            "8 540\n",
            "9 0\n",
            "9 10\n",
            "9 20\n",
            "9 30\n",
            "9 40\n",
            "9 50\n",
            "9 60\n",
            "9 70\n",
            "9 80\n",
            "9 90\n",
            "9 100\n",
            "9 110\n",
            "9 120\n",
            "9 130\n",
            "9 140\n",
            "9 150\n",
            "9 160\n",
            "9 170\n",
            "9 180\n",
            "9 190\n",
            "9 200\n",
            "9 210\n",
            "9 220\n",
            "9 230\n",
            "9 240\n",
            "9 250\n",
            "9 260\n",
            "9 270\n",
            "9 280\n",
            "9 290\n",
            "9 300\n",
            "9 310\n",
            "9 320\n",
            "9 330\n",
            "9 340\n",
            "9 350\n",
            "9 360\n",
            "9 370\n",
            "9 380\n",
            "9 390\n",
            "9 400\n",
            "9 410\n",
            "9 420\n",
            "9 430\n",
            "9 440\n",
            "9 450\n",
            "9 460\n",
            "9 470\n",
            "9 480\n",
            "9 490\n",
            "9 500\n",
            "9 510\n",
            "9 520\n",
            "9 530\n",
            "9 540\n",
            "10 0\n",
            "10 10\n",
            "10 20\n",
            "10 30\n",
            "10 40\n",
            "10 50\n",
            "10 60\n",
            "10 70\n",
            "10 80\n",
            "10 90\n",
            "10 100\n",
            "10 110\n",
            "10 120\n",
            "10 130\n",
            "10 140\n",
            "10 150\n",
            "10 160\n",
            "10 170\n",
            "10 180\n",
            "10 190\n",
            "10 200\n",
            "10 210\n",
            "10 220\n",
            "10 230\n",
            "10 240\n",
            "10 250\n",
            "10 260\n",
            "10 270\n",
            "10 280\n",
            "10 290\n",
            "10 300\n",
            "10 310\n",
            "10 320\n",
            "10 330\n",
            "10 340\n",
            "10 350\n",
            "10 360\n",
            "10 370\n",
            "10 380\n",
            "10 390\n",
            "10 400\n",
            "10 410\n",
            "10 420\n",
            "10 430\n",
            "10 440\n",
            "10 450\n",
            "10 460\n",
            "10 470\n",
            "10 480\n",
            "10 490\n",
            "10 500\n",
            "10 510\n",
            "10 520\n",
            "10 530\n",
            "10 540\n",
            "11 0\n",
            "11 10\n",
            "11 20\n",
            "11 30\n",
            "11 40\n",
            "11 50\n",
            "11 60\n",
            "11 70\n",
            "11 80\n",
            "11 90\n",
            "11 100\n",
            "11 110\n",
            "11 120\n",
            "11 130\n",
            "11 140\n",
            "11 150\n",
            "11 160\n",
            "11 170\n",
            "11 180\n",
            "11 190\n",
            "11 200\n",
            "11 210\n",
            "11 220\n",
            "11 230\n",
            "11 240\n",
            "11 250\n",
            "11 260\n",
            "11 270\n",
            "11 280\n",
            "11 290\n",
            "11 300\n",
            "11 310\n",
            "11 320\n",
            "11 330\n",
            "11 340\n",
            "11 350\n",
            "11 360\n",
            "11 370\n",
            "11 380\n",
            "11 390\n",
            "11 400\n",
            "11 410\n",
            "11 420\n",
            "11 430\n",
            "11 440\n",
            "11 450\n",
            "11 460\n",
            "11 470\n",
            "11 480\n",
            "11 490\n",
            "11 500\n",
            "11 510\n",
            "11 520\n",
            "11 530\n",
            "11 540\n",
            "12 0\n",
            "12 10\n",
            "12 20\n",
            "12 30\n",
            "12 40\n",
            "12 50\n",
            "12 60\n",
            "12 70\n",
            "12 80\n",
            "12 90\n",
            "12 100\n",
            "12 110\n",
            "12 120\n",
            "12 130\n",
            "12 140\n",
            "12 150\n",
            "12 160\n",
            "12 170\n",
            "12 180\n",
            "12 190\n",
            "12 200\n",
            "12 210\n",
            "12 220\n",
            "12 230\n",
            "12 240\n",
            "12 250\n",
            "12 260\n",
            "12 270\n",
            "12 280\n",
            "12 290\n",
            "12 300\n",
            "12 310\n",
            "12 320\n",
            "12 330\n",
            "12 340\n",
            "12 350\n",
            "12 360\n",
            "12 370\n",
            "12 380\n",
            "12 390\n",
            "12 400\n",
            "12 410\n",
            "12 420\n",
            "12 430\n",
            "12 440\n",
            "12 450\n",
            "12 460\n",
            "12 470\n",
            "12 480\n",
            "12 490\n",
            "12 500\n",
            "12 510\n",
            "12 520\n",
            "12 530\n",
            "12 540\n",
            "13 0\n",
            "13 10\n",
            "13 20\n",
            "13 30\n",
            "13 40\n",
            "13 50\n",
            "13 60\n",
            "13 70\n",
            "13 80\n",
            "13 90\n",
            "13 100\n",
            "13 110\n",
            "13 120\n",
            "13 130\n",
            "13 140\n",
            "13 150\n",
            "13 160\n",
            "13 170\n",
            "13 180\n",
            "13 190\n",
            "13 200\n",
            "13 210\n",
            "13 220\n",
            "13 230\n",
            "13 240\n",
            "13 250\n",
            "13 260\n",
            "13 270\n",
            "13 280\n",
            "13 290\n",
            "13 300\n",
            "13 310\n",
            "13 320\n",
            "13 330\n",
            "13 340\n",
            "13 350\n",
            "13 360\n",
            "13 370\n",
            "13 380\n",
            "13 390\n",
            "13 400\n",
            "13 410\n",
            "13 420\n",
            "13 430\n",
            "13 440\n",
            "13 450\n",
            "13 460\n",
            "13 470\n",
            "13 480\n",
            "13 490\n",
            "13 500\n",
            "13 510\n",
            "13 520\n",
            "13 530\n",
            "13 540\n",
            "14 0\n",
            "14 10\n",
            "14 20\n",
            "14 30\n",
            "14 40\n",
            "14 50\n",
            "14 60\n",
            "14 70\n",
            "14 80\n",
            "14 90\n",
            "14 100\n",
            "14 110\n",
            "14 120\n",
            "14 130\n",
            "14 140\n",
            "14 150\n",
            "14 160\n",
            "14 170\n",
            "14 180\n",
            "14 190\n",
            "14 200\n",
            "14 210\n",
            "14 220\n",
            "14 230\n",
            "14 240\n",
            "14 250\n",
            "14 260\n",
            "14 270\n",
            "14 280\n",
            "14 290\n",
            "14 300\n",
            "14 310\n",
            "14 320\n",
            "14 330\n",
            "14 340\n",
            "14 350\n",
            "14 360\n",
            "14 370\n",
            "14 380\n",
            "14 390\n",
            "14 400\n",
            "14 410\n",
            "14 420\n",
            "14 430\n",
            "14 440\n",
            "14 450\n",
            "14 460\n",
            "14 470\n",
            "14 480\n",
            "14 490\n",
            "14 500\n",
            "14 510\n",
            "14 520\n",
            "14 530\n",
            "14 540\n",
            "806.5352008342743\n",
            "0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
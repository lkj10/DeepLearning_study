{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Data Set Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zRdwbqdhmNm",
        "outputId": "79154be2-073f-45a8-a06b-b0941b2599e4"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.34.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVxeF-3Oh8G4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L_qjljfiJxG",
        "outputId": "53cfd03e-bd4f-4a97-e207-c20fe5addebe"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"data_MNIST\", one_hot = True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-e0b6fd23d270>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data_MNIST/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data_MNIST/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data_MNIST/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data_MNIST/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hSjb40iVPg"
      },
      "source": [
        "num_steps = 5000\n",
        "batch_size = 128\n",
        "nH1 = 256 #인풋데이터가 784인데 첫번째 히든 레이어의 node 갯수가 256개임. 왜?\n",
        "# => mnist의 데이터가 양질의 데이터이다. 그래서 가능(크기, 흑백 처리 등)\n",
        "#그래서 256개의 노드로도 딥러닝이 가능하다.\n",
        "nH2 = 256\n",
        "nH3 = 256\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, 784])\n",
        "Y = tf.placeholder(\"float\", [None, 10])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3-7_0cKjuRY"
      },
      "source": [
        "def mlp_LC(img):\n",
        "  HL1 = tf.nn.relu(tf.add(tf.matmul(img, W['HL1']), b['HL1']))\n",
        "  HL2 = tf.nn.relu(tf.add(tf.matmul(HL1, W['HL2']), b['HL2']))\n",
        "  HL3 = tf.nn.relu(tf.add(tf.matmul(HL2, W['HL3']), b['HL3']))\n",
        "  Out = tf.matmul(HL3, W['Out']) + b['Out']\n",
        "  return Out\n",
        "\n",
        "W = {\n",
        "    'HL1' : tf.Variable(tf.random_normal([784, nH1])),\n",
        "    'HL2' : tf.Variable(tf.random_normal([nH1, nH2])),\n",
        "    'HL3' : tf.Variable(tf.random_normal([nH2, nH3])),\n",
        "    'Out' : tf.Variable(tf.random_normal([nH3, 10]))\n",
        "}\n",
        "\n",
        "b = {\n",
        "    'HL1' : tf.Variable(tf.random_normal([nH1])),\n",
        "    'HL2' : tf.Variable(tf.random_normal([nH2])),\n",
        "    'HL3' : tf.Variable(tf.random_normal([nH3])),\n",
        "    'Out' : tf.Variable(tf.random_normal([10]))\n",
        "}\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9ZsmHFE7eww"
      },
      "source": [
        "def mlp_LC(img):\n",
        "  HL1 = tf.layers.dense(inputs = img, units = nH1, activation = tf.nn.relu)\n",
        "  HL2 = tf.layers.dense(inputs = HL1, units = nH2, activation = tf.nn.relu)\n",
        "  HL3 = tf.layers.dense(inputs = HL2, units = nH3, activation = tf.nn.relu)\n",
        "  Out = tf.layers.dense(inputs = HL3, units = 10, activation = None)\n",
        "  return Out"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vzox0i9j-KW",
        "outputId": "1787cea4-6f63-4b21-fa81-bbe07f34c904"
      },
      "source": [
        "model_LC = mlp_LC(X)\n",
        "model = tf.nn.softmax(model_LC)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_LC, labels = Y))\n",
        "train = tf.train.AdamOptimizer(0.01).minimize(cost)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-e1dffa40db87>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6af177dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfVzkbvRltMh"
      },
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1)), tf.float32))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiIjkz4Kosno",
        "outputId": "e6b3c217-52cb-43d5-8030-c9385c81a20f"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  #Train\n",
        "  t1 = time.time()\n",
        "  for step in range(1, num_steps + 1):\n",
        "    train_images, train_labels = mnist.train.next_batch(batch_size)\n",
        "    sess.run(train, feed_dict = {X: train_images, Y: train_labels})\n",
        "    if step % 500 == 0:\n",
        "      print(step)\n",
        "      print(sess.run(accuracy, feed_dict = {X: train_images, Y: train_labels}))\n",
        "  t2 = time.time()\n",
        "  print(t2 - t1)\n",
        "  print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "0.96875\n",
            "1000\n",
            "0.9921875\n",
            "1500\n",
            "0.9921875\n",
            "2000\n",
            "0.9765625\n",
            "2500\n",
            "0.96875\n",
            "3000\n",
            "0.9765625\n",
            "3500\n",
            "1.0\n",
            "4000\n",
            "0.9921875\n",
            "4500\n",
            "1.0\n",
            "5000\n",
            "1.0\n",
            "37.66774320602417\n",
            "0.9739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaJEyB144luV",
        "outputId": "964ce895-7f60-4fa8-fe6f-89e29a9c770b"
      },
      "source": [
        "def mlp_LC(img):\n",
        "  #HL1 = tf.nn.relu(tf.add(tf.matmul(img, W['HL1']), b['HL1']))\n",
        "  #HL2 = tf.nn.relu(tf.add(tf.matmul(HL1, W['HL2']), b['HL2']))\n",
        "  #HL3 = tf.nn.relu(tf.add(tf.matmul(HL2, W['HL3']), b['HL3']))\n",
        "  Out = tf.matmul(img, W['Out']) + b['Out']\n",
        "  return Out\n",
        "\n",
        "W = {\n",
        "    'HL1' : tf.Variable(tf.random_normal([784, nH1])),\n",
        "    'HL2' : tf.Variable(tf.random_normal([nH1, nH2])),\n",
        "    'HL3' : tf.Variable(tf.random_normal([nH2, nH3])),\n",
        "    'Out' : tf.Variable(tf.random_normal([784, 10]))\n",
        "}\n",
        "\n",
        "b = {\n",
        "    'HL1' : tf.Variable(tf.random_normal([nH1])),\n",
        "    'HL2' : tf.Variable(tf.random_normal([nH2])),\n",
        "    'HL3' : tf.Variable(tf.random_normal([nH3])),\n",
        "    'Out' : tf.Variable(tf.random_normal([10]))\n",
        "}\n",
        "\n",
        "model_LC = mlp_LC(X)\n",
        "model = tf.nn.softmax(model_LC)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_LC, labels = Y))\n",
        "train = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
        "\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1)), tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  #Train\n",
        "  t1 = time.time()\n",
        "  for step in range(1, num_steps + 1):\n",
        "    train_images, train_labels = mnist.train.next_batch(batch_size)\n",
        "    sess.run(train, feed_dict = {X: train_images, Y: train_labels})\n",
        "    if step % 500 == 0:\n",
        "      print(step)\n",
        "  t2 = time.time()\n",
        "  print(t2 - t1)\n",
        "  print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n",
            "9.793606281280518\n",
            "0.9113\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}